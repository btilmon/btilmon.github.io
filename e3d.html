<!DOCTYPE html>



 <html>

<head>
  
  <title>Brevin Tilmon</title>
  <link rel="stylesheet" type="text/css" href="style.css">
  <link rel="stylesheet" href="http://domain.tld/screen.css" type="text/css" media="Screen" />
  <link rel="stylesheet" href="http://domain.tld/mobile.css" type="text/css" media="handheld" />
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  
  <link rel="shortcut icon" href=""/> 

  
<style>
* {
  box-sizing: border-box;
}

/* Create two unequal columns that floats next to each other */
.column {
  float: left;
  padding-right: 15px;
  padding-bottom: 25px;
  height: 100%;
}

.columnR {
  float: right;
  padding-right: 0px;
  padding-bottom: 0px;
  height: 100%;
}

.left {
  width: 25%;
  padding-top: 4px;
}


.right {
  width: 75%;
}

.columnIm {
  float: left;
  padding-right: 2px;
  padding-bottom: 0px;
  height: 100%;
}

.columnImR {
  float: right;
  padding-right: 0px;
  padding-bottom: 0px;
  height: 100%;
}

.leftIm {
  width: 20%;
  padding-top: 4px;
  padding-right: 20px;
}

.rightIm {
  width: 80%;
  padding-right: 0px;
}

.leftInto {
  width: 50%;
  padding-top: 4px;
  padding-right: 20px;
}

.rightIntro {
  width: 50%;
  padding-top: 10px;
}

/* Clear floats after the columns */
.row:after {
  content: "";
  display: table;
  clear: both;
}

a{ 
  text-decoration: none; 
  color:#4682B4;
  font-weight: bold;
}

a.cvpra{
  text-decoration: none; 
  color:#4682B4;
  font-weight: normal;
}



.class1 {
  font-weight: bold;
}

.class2 {
  font-weight: normal;
}

a:hover{
  text-decoration: underline;
}

</style>

</head>

<body>
  <meta name="viewport" content="width=device-width, initial-scale=1">
<br><br>


<div class="containerCVPR">
  <!-- <div class="row">
    <div class="columnIm leftIntro">
      <h6 class="normal">Brevin Tilmon</h6> <br> 
    </div>
    <div class="columnR rightIntro" >


    </div>
  </div> -->

<p class="cvprTitle">Energy-Efficient Adaptive 3D Sensing</p><br>
<p class="cvprConf">CVPR 2023</p><br>
<p class="authors"><a class="cvpra" href="https://btilmon.github.io/">Brevin Tilmon</a><sup style="font-size:8.0pt">1</sup> &nbsp &nbsp <a class="cvpra" href="https://zhsun0357.github.io/">Zhanghao Sun</a><sup style="font-size:8.0pt">2</sup> &nbsp &nbsp <a  class="cvpra" href="https://focus.ece.ufl.edu/people/">Sanjeev Koppal</a><sup style="font-size:8.0pt">1</sup>  &nbsp &nbsp  <a  class="cvpra" href="https://yichengwu.github.io/">Yicheng Wu</a><sup style="font-size:8.0pt">3</sup><br>

    &nbsp &nbsp  <a  class="cvpra" href="https://sites.google.com/site/georgeevangelidis/">Georgios Evangelidis</a><sup style="font-size:8.0pt">3</sup> &nbsp &nbsp  <a  class="cvpra" href="https://www.linkedin.com/in/ramzi-zahreddine-42a09b87/">Ramzi Zahreddine</a><sup style="font-size:8.0pt">3</sup> &nbsp &nbsp  <a  class="cvpra" href="https://www.linkedin.com/in/krishnanguru/">Guru Krishnan</a><sup style="font-size:8.0pt">3</sup> &nbsp &nbsp  <a  class="cvpra" href="https://sizhuoma.netlify.app/">Sizhuo Ma</a><sup style="font-size:8.0pt">3</sup> &nbsp &nbsp  <a  class="cvpra" href="https://jianwang-cmu.github.io/">Jian Wang</a><sup style="font-size:8.0pt">3</sup>
</p>
<p class="authors"><sup style="font-size:8.0pt">1</sup>University of Florida &nbsp &nbsp <sup style="font-size:8.0pt">2</sup>Stanford University &nbsp &nbsp <sup style="font-size:8.0pt">3</sup>Snap Research </p>

<br>

<div class="image-container">
<a class="cvpra" href="https://btilmon.github.io/e3d.html" target="_blank">
    <figure>
        <img src="pubs/e3dpdfTeaser.png" alt="Energy-Efficient Adaptive 3D Sensing" class="paper-image">
        <figcaption>Paper (Coming Soon)</figcaption>
    </figure>
</a>

<a class="cvpra" href="https://github.com/btilmon/holoCu" target="_blank">
    <figure>
        <img src="pubs/holoCuTeaser.png" alt="Energy-Efficient Adaptive 3D Sensing" class="paper-image">
        <figcaption><a class="cvpra" href="https://github.com/btilmon/holoCu">Code</a></figcaption>
    </figure>
</a>
</div>


<br> 
<!-- <h1 class="cvprSecTitle">Abstract</h1> -->
<p class="cvprSecBody">Active depth sensing achieves robust depth estimation but is usually limited by the sensing range. Naively increasing the optical power can improve sensing range but induces eye-safety concerns for many applications, including autonomous robots and augmented reality. In this paper, we propose an adaptive active depth sensor that jointly optimizes range, power consumption, and eye-safety. The main observation is that we need not project light patterns to the entire scene but only to small regions of interest where depth is necessary for the application and passive stereo depth estimation fails. We theoretically compare this adaptive sensing scheme with other sensing strategies, such as full-frame projection, line scanning, and point scanning. We show that, to achieve the same maximum sensing distance, the proposed method consumes the least power while having the shortest (best) eye-safety distance. We implement this adaptive sensing scheme with two hardware prototypes, one with a phase-only spatial light modulator (SLM) and the other with a micro-electro-mechanical (MEMS) mirror and diffractive optical elements (DOE). Experimental results validate the advantage of our method and demonstrate its capability of acquiring higher quality geometry adaptively. </p>




</div> 


</body>
</html>
